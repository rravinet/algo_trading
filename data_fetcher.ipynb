{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('/Users/raphaelravinet/Code')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine, select, and_, or_\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from algo_trading.log_config import setup_logging\n",
    "from Fin_Database.Data.connect import engine, DailyStockData, HourlyStockData, OneMinuteStockData, FiveMinuteStockData,FifteenMinuteStockData, StockSplits, StockNews, CompanyFinancials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "# %%\n",
    "username = os.getenv(\"DATABASE_USERNAME\")\n",
    "password = os.getenv(\"DATABASE_PASSWORD\")\n",
    "host = os.getenv(\"DATABASE_HOST\")\n",
    "port = os.getenv(\"DATABASE_PORT\")\n",
    "database = os.getenv(\"DATABASE_NAME\")\n",
    "\n",
    "\n",
    "# %%\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind = engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFetcher:\n",
    "    \"\"\" This class will fetch the data from Postgres SQL using SQL Alchemy. \n",
    "    It is flexible to allow the retrieve of data from any of the tables\"\"\"\n",
    "    \n",
    "    TABLE_MAPPING = {\n",
    "        'minute': OneMinuteStockData,\n",
    "        '5minutes': FiveMinuteStockData,\n",
    "        '15minutes': FifteenMinuteStockData,\n",
    "        'hour': HourlyStockData,\n",
    "        'daily': DailyStockData\n",
    "    }\n",
    "\n",
    "    \n",
    "    def __init__(self, tickers):\n",
    "        if isinstance(tickers,str):\n",
    "            self.tickers = [tickers]\n",
    "        else:\n",
    "            self.tickers = tickers\n",
    "        \n",
    "    def apply_date_filters(self, query, table, start_date, end_date):\n",
    "        \"\"\"Helper function to apply date filters to the query\"\"\"\n",
    "        if start_date and end_date:\n",
    "            logging.info(f\"Applying date filters: start_date = {start_date}, end_date = {end_date}\")\n",
    "            query = query.filter(and_(table.date >= start_date, table.date <= end_date))\n",
    "        elif start_date:\n",
    "            logging.info(f\"Applying start date filter: start_date = {start_date}\")\n",
    "            query = query.filter(table.date >= start_date)\n",
    "        elif end_date:\n",
    "            logging.info(f\"Applying end date filter: end_date = {end_date}\")\n",
    "            query = query.filter(table.date <= end_date)\n",
    "        \n",
    "        return query\n",
    "\n",
    "\n",
    "\n",
    "    def get_stock_data(self, timespan = 'daily', start_date = None, end_date = None, combine = True):\n",
    "        logging.info(f\"Fetching stock data for ticker(s) {self.tickers} with timespan '{timespan}'\")\n",
    "        \n",
    "        table = self.TABLE_MAPPING.get(timespan)\n",
    "        \n",
    "        if not table:\n",
    "            logging.error(f\"Invalid timespan: {timespan}\")\n",
    "            raise ValueError(f\"Invalid timespan: {timespan}\")\n",
    "\n",
    "        ticker_column = getattr(table, 'ticker_column')\n",
    "        \n",
    "        if combine:\n",
    "            logging.info(f\"Combining all tickers into a single dataframe\")\n",
    "        \n",
    "            query = session.query(table).filter(getattr(table, ticker_column).in_(self.tickers))\n",
    "            query = self.apply_date_filters(query, table, start_date, end_date)\n",
    "            query = query.order_by(table.date)\n",
    "            \n",
    "            logging.info(f\"Executing query for {self.tickers}\")\n",
    "            \n",
    "            with engine.connect() as connection:\n",
    "                result = pd.read_sql(query.statement, connection)\n",
    "            \n",
    "            logging.info(f\"Succesfully fetched data for {self.tickers}\")\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            logging.info(f\"Fetching data separately for each ticker into a dictionary of DataFrames.\")\n",
    "            dataframes = {}\n",
    "            \n",
    "            for ticker in self.tickers:\n",
    "                logging.info(f\"Fetching data for ticker: {ticker}\")\n",
    "                \n",
    "                query = session.query(table).filter(getattr(table, ticker_column) == ticker)\n",
    "                query = self.apply_date_filters(query, table, start_date, end_date)\n",
    "                query = query.order_by(table.date)\n",
    "                \n",
    "                logging.info(f\"Executing query for ticker: {ticker}\")\n",
    "                with engine.connect() as connection:\n",
    "                    dataframes[ticker] = pd.read_sql(query.statement, connection)\n",
    "                \n",
    "                logging.info(f\"Successfully fetched data for ticker: {ticker}\")\n",
    "            \n",
    "            result = dataframes\n",
    "\n",
    "        return result\n",
    "            \n",
    "    def get_company_data(self, combine=True):\n",
    "        \n",
    "        if combine:\n",
    "            logging.info(f'Getting financial statement data for {self.tickers}')\n",
    "            query = session.query(CompanyFinancials).filter(CompanyFinancials.tickers.in_(self.tickers))\n",
    "            with engine.connect() as connection:\n",
    "                result = pd.read_sql(query.statement, connection)\n",
    "        else:\n",
    "            dataframes = {}\n",
    "            for ticker in self.tickers:\n",
    "                logging.info(f'Getting financial statement data for {ticker}')\n",
    "                query = session.query(CompanyFinancials).filter(CompanyFinancials.tickers.like(f'%{ticker}%'))\n",
    "                with engine.connect() as connection:\n",
    "                    dataframes[ticker] = pd.read_sql(query.statement, connection)\n",
    "            result = dataframes\n",
    "\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minute Data\n",
    "aapl_minute = get_stock_data('AAPL', 'minute')\n",
    "msft_minute = get_stock_data('MSFT', 'minute')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily data\n",
    "aapl_daily = get_stock_data('AAPL', 'daily')\n",
    "msft_daily = get_stock_data('MSFT', 'daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_minute.to_parquet('/Users/raphaelravinet/Code/algo_trading/Datasets/Minute_Data/aapl_minute.parquet', index=False)\n",
    "msft_minute.to_parquet('/Users/raphaelravinet/Code/algo_trading/Datasets/Minute_Data/msft_minute.parquet', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
